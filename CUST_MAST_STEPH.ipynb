{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q git+https://github.com/DOJO-Smart-Ways/DOJO-Beam-Transforms.git@main#egg=dojo-beam-transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amr-east-lakehouse\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from datetime import datetime\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# GCP Project\n",
    "gcp_project_id = \"amr-east-lakehouse\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = gcp_project_id\n",
    "print(gcp_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipeline_components import input_file as io\n",
    "from utils.gcp_utils import build_gcs_path, build_bq_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n"
     ]
    }
   ],
   "source": [
    "# Config Pipeline Options and Create a new Pipeline\n",
    "# pipeline_options = {'project': 'us-multi'}\n",
    "template_id = \"CUST_MAST_STEPH_material_to_refined\"\n",
    "project = \"Portfolio_Harmonization_Phase_1\"\n",
    "# Define runner type\n",
    "runner_type = 'DataFlowRunner' # use 'DataFlowRunner' for creating a template for Dataflow.\n",
    "\n",
    "pipeline_options = {\n",
    "    \"project\": gcp_project_id,\n",
    "    \"runner\": runner_type,\n",
    "    \"region\": \"us-central1\",\n",
    "    \"staging_location\": build_gcs_path(\n",
    "        \"thotasales_bucket\", \"data_flow_pipelines\", project, \"staging\"\n",
    "    ),\n",
    "    \"temp_location\": build_gcs_path(\n",
    "        \"thotasales_bucket\", \"data_flow_pipelines\", project, \"temp\"\n",
    "    ),\n",
    "    \"template_location\": build_gcs_path(\n",
    "        \"thotasales_bucket\", \"data_flow_pipelines\", project, \"template\", template_id\n",
    "    )\n",
    "}\n",
    "\n",
    "pipeline_options = PipelineOptions.from_dictionary(pipeline_options)\n",
    "pipeline = beam.Pipeline(options=pipeline_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def build_raw_material_schema():\n",
    "#     schema = [\n",
    "#         (\"customer_number\", \"STRING\"),\n",
    "#         (\"customer_name\", \"STRING\"),\n",
    "#         (\"cust_name2\", \"STRING\"),\n",
    "#         (\"alternate_name\", \"STRING\"),\n",
    "#         (\"partner_type\", \"STRING\"),\n",
    "#         (\"partner_cust_no\", \"STRING\"),\n",
    "#         (\"duns\", \"STRING\"),\n",
    "#         (\"sic_code\", \"STRING\"),\n",
    "#         (\"comp_code\", \"STRING\"),\n",
    "#         (\"del_flag\", \"STRING\"),\n",
    "#         (\"record_creation\", \"STRING\"),\n",
    "#         (\"change_date\", \"STRING\"),\n",
    "#         (\"partner_counter\", \"STRING\"),\n",
    "#         (\"primary_bill_to\", \"STRING\"),\n",
    "#         (\"street\", \"STRING\"),\n",
    "#         (\"street2\", \"STRING\"),\n",
    "#         (\"street3\", \"STRING\"),\n",
    "#         (\"rg\", \"STRING\"),\n",
    "#         (\"credit_limit\", \"STRING\"),\n",
    "#         (\"currency_code\", \"STRING\"),\n",
    "#         (\"primary_salesrep\", \"STRING\"),\n",
    "#         (\"market_class\", \"STRING\"),\n",
    "#         (\"cty\", \"STRING\"),\n",
    "#         (\"country_name\", \"STRING\"),\n",
    "#         (\"dist_channel\", \"STRING\"),\n",
    "#         (\"sales_org\", \"STRING\"),\n",
    "#         (\"pay_terms\", \"STRING\"),\n",
    "#         (\"name\", \"STRING\"),\n",
    "#         (\"SHORT_CODE\", \"STRING\"),\n",
    "#         (\"UPDATE_DATE\", \"DATE\")\n",
    "#     ]\n",
    "#     return build_bq_schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'Raw Material' Query\n",
    "# Dummy function 'get_rm_result_query' for query generation (replace with your actual function)\n",
    "def get_rm_result_query(table_name):\n",
    "    return f\"\"\"\n",
    "WITH Watermark AS (\n",
    "  SELECT \n",
    "    IF(watermark_date IS NULL, DATE '1900-01-01', watermark_date) AS watermark_date\n",
    "  FROM (\n",
    "    SELECT \n",
    "      MAX(DATE_SUB(UPDATE_DATE, INTERVAL 2 DAY)) AS watermark_date\n",
    "    FROM \n",
    "      `{gcp_project_id}.refined.{table_name}`\n",
    "  )\n",
    ")\n",
    "SELECT\n",
    "    cust.customer_number,\n",
    "    cust.customer_name,\n",
    "    cust.cust_name2,\n",
    "    cust.alternate_name,\n",
    "    cust.partner_type,\n",
    "    cust.partner_cust_no,\n",
    "    cust.duns,\n",
    "    cust.sic_code,\n",
    "    cust.comp_code,\n",
    "    cust.del_flag,\n",
    "    cust.record_creation,\n",
    "    cust.change_date,\n",
    "    cust.partner_counter,\n",
    "    cust.primary_bill_to,\n",
    "    cust.street,\n",
    "    cust.street2,\n",
    "    cust.street3,\n",
    "    cust.rg,\n",
    "    cust.credit_limit,\n",
    "    cust.currency_code,\n",
    "    cust.primary_salesrep,\n",
    "    cust.market_class,\n",
    "    cust.cty,\n",
    "    cust.country_name,\n",
    "    cust.dist_channel,\n",
    "    cust.sales_org,\n",
    "    cust.pay_terms,\n",
    "    cust.name,\n",
    "    cust.SHORT_CODE,\n",
    "    cust.UPDATE_DATE\n",
    "FROM (\n",
    "  SELECT DISTINCT\n",
    "    hca.account_number AS customer_number,\n",
    "    hp.party_name AS customer_name,\n",
    "    REGEXP_REPLACE(hca.account_name, r'\\s+', ' ') AS cust_name2,\n",
    "    hp.known_as2 AS alternate_name,\n",
    "    hp.party_type AS partner_type,\n",
    "    hp.party_number AS partner_cust_no,\n",
    "    hp.duns_number AS duns,\n",
    "    hp.sic_code AS sic_code,\n",
    "    CASE \n",
    "      WHEN hou.SHORT_CODE = 'LEX' THEN '4001'\n",
    "      WHEN hou.SHORT_CODE = 'KTO' THEN '4000'\n",
    "      WHEN hou.SHORT_CODE = 'LPD' THEN '4002'\n",
    "      ELSE gl.segment1\n",
    "    END AS comp_code,\n",
    "    CASE \n",
    "      WHEN hca.status = 'I' THEN 'Y' \n",
    "      ELSE 'N' \n",
    "    END AS del_flag,\n",
    "    FORMAT_DATE('%d-%b-%Y', hca.creation_date) AS record_creation,\n",
    "    FORMAT_DATE('%d-%b-%Y', hca.last_update_date) AS change_date,\n",
    "    hps.party_site_number AS partner_counter,\n",
    "    hcasa.bill_to_flag AS primary_bill_to,\n",
    "    hl.address1 AS street,\n",
    "    hl.address2 AS street2,\n",
    "    hl.address3 AS street3,\n",
    "    hl.state AS rg,\n",
    "    hcpa.trx_credit_limit AS credit_limit,\n",
    "    hcpa.currency_code,\n",
    "    jrs.salesrep_number AS primary_salesrep,\n",
    "    hcsua.attribute1 AS market_class,\n",
    "    hl.county AS cty,\n",
    "    hl.country AS country_name,\n",
    "    hca.sales_channel_code AS dist_channel,\n",
    "    hou.name AS sales_org,\n",
    "    rt.name AS pay_terms,\n",
    "    hou.name,\n",
    "    hou.SHORT_CODE,\n",
    "    CURRENT_DATE() AS UPDATE_DATE\n",
    "  FROM\n",
    "    `{gcp_project_id}.transient.steph_hz_parties` hp\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_hz_party_sites` hps \n",
    "      ON hp.party_id = hps.party_id\n",
    "      AND (CAST(hp.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark) \n",
    "      OR CAST(hps.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark))\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_hz_locations` hl \n",
    "      ON hl.location_id = hps.location_id\n",
    "      AND CAST(hl.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_hz_cust_accounts` hca \n",
    "      ON hca.party_id = hp.party_id\n",
    "      AND CAST(hca.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_hz_cust_acct_sites_all` hcasa \n",
    "      ON hca.cust_account_id = hcasa.cust_account_id\n",
    "      AND CAST(hcasa.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_hz_cust_site_uses_all` hcsua \n",
    "      ON hcsua.cust_acct_site_id = hcasa.cust_acct_site_id \n",
    "      AND hcsua.site_use_code = 'BILL_TO'\n",
    "      AND CAST(hcsua.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_gl_code_combinations` gl\n",
    "      ON gl.code_combination_id = hcsua.gl_id_rev\n",
    "      AND CAST(gl.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_hr_operating_units` hou \n",
    "      ON hou.organization_id = hcsua.org_id\n",
    "      AND CAST(hou.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  JOIN \n",
    "    `{gcp_project_id}.transient.steph_ra_terms` rt \n",
    "      ON rt.organization_id = hcsua.org_id\n",
    "      AND CAST(rt.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  LEFT JOIN \n",
    "    `{gcp_project_id}.transient.steph_jtf_rs_salesreps` jrs \n",
    "      ON hcsua.primary_salesrep_id = jrs.salesrep_id \n",
    "      AND hcsua.org_id = jrs.org_id\n",
    "      AND CAST(jrs.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      hr.subject_id,\n",
    "      hpg.party_name\n",
    "    FROM\n",
    "      `{gcp_project_id}.transient.steph_hz_relationships` hr\n",
    "    JOIN \n",
    "      `{gcp_project_id}.transient.steph_hz_parties` hpg \n",
    "        ON hpg.party_id = hr.object_id\n",
    "        AND (CAST(hr.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark) \n",
    "        OR CAST(hpg.last_update_date AS DATE) > (SELECT watermark_date FROM Watermark))\n",
    "    WHERE\n",
    "      hr.status = 'A'\n",
    "      AND hr.object_table_name = 'HZ_PARTIES'\n",
    "      AND hr.subject_table_name = 'HZ_PARTIES'\n",
    "      AND hr.relationship_code IN ('MEMBER_OF', 'CHILD_OF')\n",
    "  ) hpgrp \n",
    "    ON hp.party_id = hpgrp.subject_id\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      `{gcp_project_id}.transient.steph_hz_customer_profiles`\n",
    "    WHERE\n",
    "      site_use_id IS NULL\n",
    "      AND CAST(last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  ) hcp \n",
    "    ON rt.term_id = hcp.standard_terms\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      `{gcp_project_id}.transient.steph_hz_cust_profile_amts`\n",
    "    WHERE\n",
    "      currency_code = 'USD'\n",
    "      AND CAST(last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  ) hcpa \n",
    "    ON hca.cust_account_id = hcpa.cust_account_id\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      term_id,\n",
    "      MAX(due_days) AS due_days\n",
    "    FROM\n",
    "      `{gcp_project_id}.transient.steph_ra_terms_lines`\n",
    "    WHERE \n",
    "      CAST(last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "    GROUP BY term_id\n",
    "  ) rtl \n",
    "    ON rt.term_id = rtl.term_id\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      acra.pay_from_customer,\n",
    "      acra.org_id,\n",
    "      acra.amount,\n",
    "      FORMAT_DATE('%d-%b-%Y', acra.receipt_date) AS receipt_date\n",
    "    FROM\n",
    "      `{gcp_project_id}.transient.steph_ar_cash_receipts_all` acra\n",
    "    WHERE\n",
    "      acra.cash_receipt_id = (\n",
    "        SELECT\n",
    "          MAX(cash_receipt_id)\n",
    "        FROM\n",
    "          `{gcp_project_id}.transient.steph_ar_cash_receipts_all` acram\n",
    "        WHERE\n",
    "          acram.org_id = acra.org_id\n",
    "          AND acram.pay_from_customer = acra.pay_from_customer\n",
    "          AND CAST(last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "      )\n",
    "      AND CAST(last_update_date AS DATE) > (SELECT watermark_date FROM Watermark)\n",
    "  ) acra \n",
    "    ON hcasa.org_id = acra.org_id \n",
    "    AND hcasa.cust_account_id = acra.pay_from_customer\n",
    "  WHERE\n",
    "  cust.comp_code='4002' OR\n",
    "    (cust.SHORT_CODE IN ('LEX', 'KTO', 'LPD'))\n",
    ") cust\n",
    "ORDER BY\n",
    "  cust.customer_number,\n",
    "  cust.partner_counter;\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Main function of the Pipeline\n",
    "def run_pipeline(temp_location, output_table,table_name):\n",
    "    # Get the queries\n",
    "    query = get_rm_result_query(table_name)\n",
    "\n",
    "    # Read from BigQuery\n",
    "    read_rw = io.read_bq(\n",
    "        pipeline,\n",
    "        query,\n",
    "        temp_location,\n",
    "        identifier=\"CUST_MAST STEPH Phase 1\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Write to BigQuery\n",
    "    read_rw | \"Write To BigQuery\" >> beam.io.WriteToBigQuery(\n",
    "        output_table,\n",
    "        # schema=build_raw_material_schema(),\n",
    "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,\n",
    "        custom_gcs_temp_location = temp_location,\n",
    "    )\n",
    "\n",
    "    pipeline.run().wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    div.alert {\n",
       "      white-space: pre-line;\n",
       "    }\n",
       "  </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
       "            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://thotasales_bucket/data_flow_pipelines_hrm_test/Portfolio_Harmonization_Phase_1/staging for cache location.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-96233403-2bf1-4e7f-8c7b-dcb11523632e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    output_table = \"amr-east-lakehouse.refined.hrm_steph_custmast\"\n",
    "    table_name = 'hrm_steph_custmast'\n",
    "    temp_location = build_gcs_path(\"thotasales_bucket\", \"data_flow_pipelines\", \"Portfolio_Harmonization_Phase_1\", \"temp\")\n",
    "    run_pipeline(temp_location, output_table, table_name)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
